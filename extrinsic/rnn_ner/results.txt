NOTE: this .txt file was not-autogenerated by a script. 

Results obtained by training a Bi-LSTM-CRF on the CoNLL03 dataset, with embeddings produced by our trained LOVE model.

best f1 on dev-set: 80.96 (vs. 78.6 of the paper)
train total cost: 31m 35s

Evalution of the best model (f1 = 80.96) on the test set:
46666 tokens with 5648 phrases. Found 5057 phrases (4166 correct)

accuracy: 95.01%, precision: 82.38%, recall: 73.76%, FB1: 77.83

test acc on test set 77.83
