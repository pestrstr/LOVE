NOTE: this .txt file was not-autogenerated by a script. 

############################
Results obtained by training a Bi-LSTM-CRF on the CoNLL03 dataset, with embeddings produced by our trained LOVE model.

best f1 on dev-set: 80.96 (vs. 78.6 of the paper)
train total cost: 31m 35s

Evaluation of the best model (f1 = 80.96) on the test set:
46666 tokens with 5648 phrases. Found 5057 phrases (4166 correct)

accuracy: 95.01%, precision: 82.38%, recall: 73.76%, FB1: 77.83

test acc on test set 77.83

############################
Results obtained by training a Bi-LSTM-CRF on the CoNLL03 dataset, with embeddings produced by the provided LOVE+FastText model.

best f1 on dev-set: 82.7 
train total cost: 27m 56s (early stop)

Evaluation of the best model (f1 = 82.7) on the test set:
46666 tokes with 5648 phrases. Found 5086 phrases (4294 correct)

accuracy: 95.36%, precision 84.43%, recall: 76.03%, FB2: 80.01

test acc on test set 80.01

############################
Results obtained by training a Bi-LSTM-CRF on the CoNLL03 dataset, with embeddings produced by the provided LOVE+BERT model.

best f1 on dev-set: 80.17 
train total cost: 25m 46s (early stop)

Evaluation of the best model (f1 = 80.17) on the test set:
46666 tokes with 5648 phrases. Found 4996 phrases (4088 correct)

accuracy: 94.66%, precision 81.83%, recall: 72.38%, FB2: 76.81

test acc on test set 76.81
